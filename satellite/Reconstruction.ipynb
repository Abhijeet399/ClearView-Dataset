{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSbFH4xvZWwe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.python.framework import ops\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tensorflow.core.protobuf import config_pb2\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShAQGPq5by91",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data(i):\n",
    "    training_data=[]\n",
    "    training_data_bw=[]\n",
    "    for j in range((i*124),(124+(i*124))):\n",
    "        image = cv2.imread('D:\\satellitedata\\shufflenoisydata\\%d.jpg' %(j))\n",
    "        new_array=cv2.resize(image,(512,512))\n",
    "        norm_img = np.zeros((512,512))\n",
    "        final_img = cv2.normalize(new_array,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        new_array = final_img\n",
    "        new_array_bw = cv2.cvtColor(new_array, cv2.COLOR_BGR2GRAY)\n",
    "        new_array_bw = cv2.resize(new_array_bw,(512,512))\n",
    "        new_array_bw = np.reshape(new_array_bw, (512,512,1))\n",
    "        training_data.append(new_array)\n",
    "        training_data_bw.append(new_array_bw)\n",
    "    return training_data, training_data_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(i):\n",
    "    label = []\n",
    "    for j in range((i*124),(124+(i*124))):\n",
    "        image = cv2.imread('D:\\\\satellitedata\\\\shufflelabel\\\\%d.jpg' %(j))\n",
    "        new_array=cv2.resize(image,(512,512))\n",
    "        norm_img = np.zeros((512,512))\n",
    "        final_img = cv2.normalize(new_array, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        new_array = final_img\n",
    "        label.append(new_array)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_EJU5gPFZYjl"
   },
   "outputs": [],
   "source": [
    "# def discriminator(img,reuse=None):\n",
    "#     with tf.variable_scope('dis',reuse=reuse):\n",
    "#         flat = tf.contrib.layers.flatten(img)\n",
    "#         # print(np.shape(flat))\n",
    "#         hidden_1 = tf.layers.dense(inputs=flat,units=128, activation=tf.nn.leaky_relu, name='hidden_1')\n",
    "#         hidden_2 = tf.layers.dense(inputs=hidden_1,units=128, activation=tf.nn.leaky_relu, name='hidden_2')\n",
    "#         hidden_3=tf.layers.dense(inputs=hidden_2,units=128,activation=tf.nn.leaky_relu)\n",
    "#         hidden_4=tf.layers.dense(inputs=hidden_3,units=128,activation=tf.nn.leaky_relu)\n",
    "#         logits= tf.layers.dense(inputs=hidden_4, units=1)\n",
    "#         output=tf.sigmoid(logits)\n",
    "#     return output,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(img,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden_1 = tf.layers.conv2d(img,20, (3,3),strides=(2, 2), padding='valid', activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        hidden_2 = tf.layers.conv2d(hidden_1, 30, (3,3),strides=(2, 2), padding='valid', activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        hidden_3= tf.layers.conv2d(hidden_2, 40, (3,3),strides=(2, 2), padding='valid', activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        hidden_4= tf.layers.conv2d(hidden_3, 30, (5,5),strides=(2, 2), padding='valid', activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        flat = tf.contrib.layers.flatten(hidden_4)\n",
    "        hidden_5=tf.layers.dense(inputs=flat,units=500,activation=tf.nn.leaky_relu)\n",
    "        logits= tf.layers.dense(inputs=hidden_5, units=1)\n",
    "        output=tf.sigmoid(logits)\n",
    "    return output,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWOr8qCdZbad"
   },
   "outputs": [],
   "source": [
    "# X_noisy = tf.placeholder(tf.float32, (None, 1024, 1024, 3), name='inputs')\n",
    "# X_noisy_bw = tf.placeholder(tf.float32, (None, 1024, 1024, 1), name='inputs')\n",
    "# X_label = tf.placeholder(tf.float32, (None, 1024, 1024, 3), name='targets')\n",
    "# filters = {1:20,2:20,3:60, 4:60, 5:60, 6:60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_noisy = tf.placeholder(tf.float32, (None, 512, 512, 3), name='inputs')\n",
    "X_noisy_bw = tf.placeholder(tf.float32, (None, 512, 512, 1), name='inputs')\n",
    "X_label = tf.placeholder(tf.float32, (None, 512, 512, 3), name='targets')\n",
    "filters = {1:20,2:20,3:60, 4:60, 5:60, 6:60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9mmGKvNaNMZ"
   },
   "outputs": [],
   "source": [
    "def AutoEncoder(X_noisy, X_noisy_bw, reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        ### Encoder\n",
    "        conv1 = tf.layers.conv2d(X_noisy, filters[1], (3,3),strides=(2, 2), padding='valid', activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        conv2 = tf.layers.conv2d(X_noisy_bw, filters[2], (3,3),strides=(2,2),padding='valid',activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        conv = tf.concat([conv1, conv2], 3)\n",
    "        conv_shortcut = conv\n",
    "        convD1 = tf.layers.conv2d(conv2,filters[4],(3,3), strides=(1, 1), padding='valid',dilation_rate=(2, 2), activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        convD2 = tf.layers.conv2d(convD1,filters[5],(5,5), strides=(1, 1), padding='valid',dilation_rate=(3, 3), activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())        \n",
    "        conv_shortcut1 = tf.layers.conv2d(conv_shortcut, 60, (17,17),strides=(1,1), padding='valid', activation=tf.nn.relu)\n",
    "        print(np.shape(convD2))\n",
    "        print(np.shape(conv_shortcut1))\n",
    "        print(np.shape(conv_shortcut))\n",
    "        convx = tf.math.add(convD2, conv_shortcut1)\n",
    "        ###Decoder\n",
    "        upsample1 = tf.image.resize_nearest_neighbor(convx, (384,384))\n",
    "        conv4 = tf.layers.conv2d(upsample1, 40, (7,7), padding='same',activation=tf.nn.relu)\n",
    "        upsample2 = tf.image.resize_nearest_neighbor(conv4, (440,440))\n",
    "        conv5 = tf.layers.conv2d(upsample2, 20, (5,5), padding='same',activation=tf.nn.relu)\n",
    "        upsample3 = tf.image.resize_nearest_neighbor(conv5, (512,512))\n",
    "        conv6 = tf.layers.conv2d(upsample3, 3, (3,3), padding='same',activation=tf.nn.relu)\n",
    "        print(np.shape(conv6))\n",
    "        return conv6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "oRREcNsvCTlY",
    "outputId": "40e06406-51b3-473c-a492-8fc7f2f3ee73",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-4f52db68326c>:4: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "(?, 239, 239, 60)\n",
      "(?, 239, 239, 60)\n",
      "(?, 255, 255, 40)\n",
      "(?, 512, 512, 3)\n",
      "(?, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "conv6 = AutoEncoder(X_noisy, X_noisy_bw)\n",
    "print(np.shape(conv6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "4IFTITl0cLrP",
    "outputId": "1219ee63-6d5b-4587-8f87-17ad535c5bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-d987d1c9b658>:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "D_output_real,D_logits_real=discriminator(X_label)\n",
    "D_output_fake,D_logits_fake=discriminator(conv6,reuse=True)\n",
    "\n",
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))\n",
    "\n",
    "D_real_loss=loss_func(D_logits_real,tf.ones_like(D_logits_real)*0.9) #Smoothing for generalization\n",
    "D_fake_loss=loss_func(D_logits_fake,tf.zeros_like(D_logits_real))\n",
    "\n",
    "D_loss=D_real_loss+D_fake_loss\n",
    "\n",
    "G_loss= loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "_6vhlVdpmV6I",
    "outputId": "740d67ed-968e-402d-ef83-da49bf1b1fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_dis/conv2d/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d_1/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d_2/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d_2/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d_3/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/conv2d_3/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/dense/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/dense/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/dense_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dis/dense_1/bias/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "name: \"Adam_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_1/update_gen/conv2d/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_1/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_2/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_2/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_3/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_3/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_4/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_4/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_5/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_5/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_6/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_6/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_7/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_gen/conv2d_7/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/Assign\"\n",
      "input: \"^Adam_1/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=0.0001\n",
    "\n",
    "#Do this when multiple networks interact with each other\n",
    "tvars=tf.trainable_variables()  #returns all variables created(the two variable scopes) and makes trainable true\n",
    "d_vars=[var for var in tvars if 'dis' in var.name]\n",
    "g_vars=[var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "D_trainer=tf.train.AdamOptimizer(lr).minimize(D_loss,var_list=d_vars)\n",
    "print(D_trainer)\n",
    "G_trainer=tf.train.AdamOptimizer(lr).minimize(G_loss,var_list=g_vars)\n",
    "print(G_trainer)\n",
    "\n",
    "batch_size=124\n",
    "totalsize = 21080\n",
    "epochs=10\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "5NnBshuGcwPz",
    "outputId": "78040ab4-fdb3-4690-86b5-9244f21c8c95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[62,384,384,60] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gen/ResizeNearestNeighbor (defined at e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[62,384,384,60] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gen/ResizeNearestNeighbor (defined at e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[add/_15]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'gen/ResizeNearestNeighbor':\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-f5aa022e4a42>\", line 1, in <module>\n    conv6 = AutoEncoder(X_noisy, X_noisy_bw)\n  File \"<ipython-input-8-4f52db68326c>\", line 16, in AutoEncoder\n    upsample1 = tf.image.resize_nearest_neighbor(convx, (384,384))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\image_ops_impl.py\", line 3573, in resize_nearest_neighbor\n    name=name)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_image_ops.py\", line 3658, in resize_nearest_neighbor\n    name=name)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[62,384,384,60] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gen/ResizeNearestNeighbor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[62,384,384,60] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gen/ResizeNearestNeighbor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[add/_15]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f80a401d99b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#             Y = label[i*batch_size:batch_size+(i*batch_size)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_d_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mD_trainer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX_label\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_noisy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_noisy_bw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_bw\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_g_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mG_trainer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX_noisy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_noisy_bw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_bw\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[62,384,384,60] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gen/ResizeNearestNeighbor (defined at e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[62,384,384,60] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gen/ResizeNearestNeighbor (defined at e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[add/_15]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'gen/ResizeNearestNeighbor':\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n    self._run_once()\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n    handle._run()\n  File \"C:\\Users\\VergilCrimson\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-f5aa022e4a42>\", line 1, in <module>\n    conv6 = AutoEncoder(X_noisy, X_noisy_bw)\n  File \"<ipython-input-8-4f52db68326c>\", line 16, in AutoEncoder\n    upsample1 = tf.image.resize_nearest_neighbor(convx, (384,384))\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\image_ops_impl.py\", line 3573, in resize_nearest_neighbor\n    name=name)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_image_ops.py\", line 3658, in resize_nearest_neighbor\n    name=name)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"e:\\dl\\satellite\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "samples=[] #generator examples\n",
    "Gcost = []\n",
    "Dcost = []\n",
    "minibatch_Dloss=0\n",
    "minibatch_Gloss=0\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, options=config_pb2.RunOptions(\n",
    "        report_tensor_allocations_upon_oom=True))\n",
    "    print(\"Session created\")\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        num_batches = 170\n",
    "        for i in range(num_batches):\n",
    "#             X = training_data[i*batch_size:batch_size+(i*batch_size)]\n",
    "            X, X_bw = data(i)\n",
    "#             X_bw = training_data_bw[i*batch_size:batch_size+(i*batch_size)]\n",
    "            Y = label(i)\n",
    "#             Y = label[i*batch_size:batch_size+(i*batch_size)]\n",
    "            \n",
    "            _, temp_d_loss = sess.run([D_trainer,D_loss], feed_dict={X_label:Y,X_noisy:X, X_noisy_bw:X_bw})\n",
    "            _, temp_g_loss = sess.run([G_trainer,G_loss], feed_dict={X_noisy:X, X_noisy_bw:X_bw})\n",
    "\n",
    "            minibatch_Dloss += temp_d_loss / num_batches\n",
    "            minibatch_Gloss += temp_g_loss / num_batches\n",
    "        \n",
    "            \n",
    "        print(\"on epoch{}\".format(epoch))\n",
    "        # Print the cost every epoch\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, minibatch_Dloss))\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, minibatch_Gloss))\n",
    "        Gcost.append(minibatch_Gloss)\n",
    "        Dcost.append(minibatch_Dloss)\n",
    "        \n",
    "        # sample_z=np.random.uniform(-1,1,size=(1,100))\n",
    "        # gen_sample=sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        # samples.append(gen_sample)\n",
    "\n",
    "# plt.imshow(samples[0].reshape(1024,1024))\n",
    "# plt.imshow(samples[99].reshape(1024,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SfVgmtlczAo"
   },
   "outputs": [],
   "source": [
    "plt.plot(Gcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Dcost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reconstruction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
