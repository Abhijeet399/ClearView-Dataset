{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.python.framework import ops\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tensorflow.core.protobuf import config_pb2\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = 1024\n",
    "# z_dim = \n",
    "x_input = tf.placeholder(tf.float32, (None, img_shape, img_shape, 3), name='Input')\n",
    "x_input_bw = tf.placeholder(tf.float32, (None, img_shape, img_shape, 1), name='Input_bw')\n",
    "x_input_mask = tf.placeholder(tf.float32, (None, img_shape, img_shape, 1), name='Input_mask')\n",
    "x_target = tf.placeholder(tf.float32, (None, img_shape, img_shape, 3), name='Target')\n",
    "# decoder_input = tf.placeholder(dtype=tf.float32, shape=[1, z_dim], name='Decoder_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datanoisefree(i):\n",
    "    training_data=[]\n",
    "    training_data_bw=[]\n",
    "    for j in range((i*1),(1+(i*1))):\n",
    "        image = cv2.imread('D:\\satellitedataCopy\\shufflelabel\\%d.jpg' %(j))\n",
    "        new_array=cv2.resize(image,(img_shape,img_shape))\n",
    "        norm_img = np.zeros((img_shape,img_shape))\n",
    "        final_img = cv2.normalize(new_array,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        new_array = final_img\n",
    "        new_array_bw = cv2.cvtColor(new_array, cv2.COLOR_BGR2GRAY)\n",
    "        new_array_bw = cv2.resize(new_array_bw,(img_shape,img_shape))\n",
    "        new_array_bw = np.reshape(new_array_bw, (img_shape,img_shape,1))\n",
    "        training_data.append(new_array)\n",
    "        training_data_bw.append(new_array_bw)\n",
    "    return training_data, training_data_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data(i):\n",
    "#     training_data=[]\n",
    "#     training_data_bw=[]\n",
    "#     for j in range((i*124),(124+(i*124))):\n",
    "#         image = cv2.imread('D:\\satellitedata\\shufflenoisydata\\%d.jpg' %(j))\n",
    "#         new_array=cv2.resize(image,(512,512))\n",
    "#         norm_img = np.zeros((512,512))\n",
    "#         final_img = cv2.normalize(new_array,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "#         new_array = final_img\n",
    "#         new_array_bw = cv2.cvtColor(new_array, cv2.COLOR_BGR2GRAY)\n",
    "#         new_array_bw = cv2.resize(new_array_bw,(512,512))\n",
    "#         new_array_bw = np.reshape(new_array_bw, (512,512,1))\n",
    "#         training_data.append(new_array)\n",
    "#         training_data_bw.append(new_array_bw)\n",
    "#     return training_data, training_data_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafornoisyimages(i):\n",
    "    training_data=[]\n",
    "    training_data_bw=[]\n",
    "    training_data_mask=[]\n",
    "    for j in range((i*124),(124+(i*124))):\n",
    "        image = cv2.imread('D:\\satellitedata\\shufflednoisedata\\%d.jpg' %(j))\n",
    "        mask_image = cv2.imread('D:\\satellitedata\\shufflemask\\%d.jpg' %(j))\n",
    "        \n",
    "        new_array=cv2.resize(image,(img_shape,img_shape))\n",
    "        norm_img = np.zeros((img_shape,img_shape))\n",
    "        final_img = cv2.normalize(new_array,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        new_array = final_img\n",
    "        \n",
    "        mask_array = cv2.normalize(mask_image,  norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "        mask_array = cv2.resize(mask_array, (img_shape,img_shape)).reshape((img_shape,img_shape,1))\n",
    "        \n",
    "        new_array_bw = cv2.cvtColor(new_array, cv2.COLOR_BGR2GRAY)\n",
    "        new_array_bw = cv2.resize(new_array_bw,(img_shape,img_shape))\n",
    "        new_array_bw = np.reshape(new_array_bw, (img_shape,img_shape,1))\n",
    "        \n",
    "        training_data.append(new_array)\n",
    "        training_data_bw.append(new_array_bw)\n",
    "        training_data_mask.append(mask_array)\n",
    "    return training_data, training_data_bw, training_data_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def label(i):\n",
    "#     label = []\n",
    "#     for j in range((i*124),(124+(i*124))):\n",
    "#         image = cv2.imread('D:\\\\satellitedata\\\\shufflelabel\\\\%d.jpg' %(j))\n",
    "#         new_array=cv2.resize(image,(512,512))\n",
    "#         norm_img = np.zeros((512,512))\n",
    "#         final_img = cv2.normalize(new_array, norm_img, 0, 255, cv2.NORM_MINMAX)\n",
    "#         new_array = final_img\n",
    "#         label.append(new_array)\n",
    "#     return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder network for noise-free(nf) images\n",
    "def encoder_nf(z,z_bw):\n",
    "    filters = {1:20,2:20,3:60, 4:60, 5:60, 6:60}\n",
    "    conv1 = tf.layers.conv2d(z, filters[1], (3,3),strides=(2, 2), padding='valid',activation=None, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv2 = tf.layers.conv2d(z_bw, filters[2], (3,3),strides=(2,2),padding='valid',activation=None,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv = tf.concat([conv1, conv2], 3)\n",
    "    convshortcut = conv\n",
    "    conv3 = tf.layers.conv2d(conv, filters[3],(5,5), strides=(2, 2), padding='valid', activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv4 = tf.layers.conv2d(conv3, filters[3],(5,5), strides=(2, 2), padding='valid', activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    convD1 = tf.layers.conv2d(conv4,filters[4],(5,5), strides=(1, 1), padding='valid',activation=tf.nn.relu,dilation_rate=(2, 2), use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    convD2 = tf.layers.conv2d(convD1,filters[4],(5,5), strides=(1, 1), padding='valid',activation=None,dilation_rate=(2, 2), use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv_shortcut1 = tf.layers.conv2d(convshortcut,filters[4],(79,79), strides=(4, 4), padding='valid',activation=None,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    print(np.shape(convD2))\n",
    "    print(np.shape(convshortcut))\n",
    "    print(np.shape(conv_shortcut1))\n",
    "    latent_variable = tf.math.add(convD2, conv_shortcut1)\n",
    "    # e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, 'e_dense_1'))\n",
    "    # e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, 'e_dense_2'))\n",
    "    # latent_variable = dense(e_dense_2, n_l2, z_dim, 'e_latent_variable')\n",
    "    return latent_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder network for noisy(n) images\n",
    "def encoder_n(z,z_bw, z_mask):\n",
    "    filters = {1:20,2:20,3:60, 4:60, 5:60, 6:60}\n",
    "    conv1 = tf.layers.conv2d(z, filters[1], (3,3),strides=(2, 2), padding='valid',activation=None, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv2 = tf.layers.conv2d(z_bw, filters[2], (3,3),strides=(2,2),padding='valid',activation=None,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv0 = tf.layers.conv2d(z_mask, filters[2], (3,3),strides=(2,2),padding='valid',activation=None,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv = tf.concat([conv1, conv2, conv0], 3)\n",
    "    convshortcut = conv\n",
    "    conv3 = tf.layers.conv2d(conv, filters[3],(5,5), strides=(2, 2), padding='valid', activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv4 = tf.layers.conv2d(conv3, filters[3],(5,5), strides=(2, 2), padding='valid', activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    convD1 = tf.layers.conv2d(conv4,filters[4],(5,5), strides=(1, 1), padding='valid',activation=tf.nn.relu,dilation_rate=(2, 2), use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    convD2 = tf.layers.conv2d(convD1,filters[4],(5,5), strides=(1, 1), padding='valid',activation=None,dilation_rate=(2, 2), use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv_shortcut1 = tf.layers.conv2d(convshortcut,filters[4],(79,79), strides=(4, 4), padding='valid',activation=None,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    print(np.shape(convD2))\n",
    "    print(np.shape(conv_shortcut1))\n",
    "    latent_variable = tf.math.add(convD2, conv_shortcut1)\n",
    "    # e_dense_1 = tf.nn.relu(dense(x, input_dim, n_l1, 'e_dense_1'))\n",
    "    # e_dense_2 = tf.nn.relu(dense(e_dense_1, n_l1, n_l2, 'e_dense_2'))\n",
    "    # latent_variable = dense(e_dense_2, n_l2, z_dim, 'e_latent_variable')\n",
    "    return latent_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_nf(x):\n",
    "    act = tf.nn.relu(x)\n",
    "    upsample1 = tf.image.resize_nearest_neighbor(act, (512,512))\n",
    "    conv5 = tf.layers.conv2d(upsample1, 40, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    upsample2 = tf.image.resize_nearest_neighbor(conv5, (636,636))\n",
    "    conv6 = tf.layers.conv2d(upsample2, 20, (5,5), padding='same',activation=tf.nn.relu)\n",
    "    upsample3 = tf.image.resize_nearest_neighbor(conv6, (776,776))\n",
    "    conv7 = tf.layers.conv2d(upsample3, 3, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    upsample4 = tf.image.resize_nearest_neighbor(conv7, (1024,1024))\n",
    "    output = tf.layers.conv2d(upsample4, 3, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    # d_dense_1 = tf.nn.relu(dense(x, z_dim, n_l2, 'd_dense_1'))\n",
    "    # d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, 'd_dense_2'))\n",
    "    # output = tf.nn.sigmoid(dense(d_dense_2, n_l1, input_dim, 'd_output'))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_n(x):\n",
    "    act = tf.nn.relu(x)\n",
    "    upsample1 = tf.image.resize_nearest_neighbor(act, (512,512))\n",
    "    conv5 = tf.layers.conv2d(upsample1, 40, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    upsample2 = tf.image.resize_nearest_neighbor(conv4, (636,636))\n",
    "    conv6 = tf.layers.conv2d(upsample2, 20, (5,5), padding='same',activation=tf.nn.relu)\n",
    "    upsample3 = tf.image.resize_nearest_neighbor(conv5, (776,776))\n",
    "    conv7 = tf.layers.conv2d(upsample3, 3, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    upsample4 = tf.image.resize_nearest_neighbor(conv5, (1024,1024))\n",
    "    output = tf.layers.conv2d(upsample4, 3, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    # d_dense_1 = tf.nn.relu(dense(x, z_dim, n_l2, 'd_dense_1'))\n",
    "    # d_dense_2 = tf.nn.relu(dense(d_dense_1, n_l2, n_l1, 'd_dense_2'))\n",
    "    # output = tf.nn.sigmoid(dense(d_dense_2, n_l1, input_dim, 'd_output'))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-84f8abd1a03d>:4: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\VergilCrimson\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\VergilCrimson\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "(?, 109, 109, 60)\n",
      "(?, 511, 511, 40)\n",
      "(?, 109, 109, 60)\n",
      "(?, 1024, 1024, 3)\n",
      "(?, 109, 109, 60)\n"
     ]
    }
   ],
   "source": [
    "encoder_output = encoder_nf(x_input, x_input_bw)\n",
    "decoder_output = decoder_nf(encoder_output)\n",
    "print(np.shape(decoder_output))\n",
    "print(np.shape(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "autoencoder_loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n",
    "autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=lr,\n",
    "                                                   beta1=0.9).minimize(autoencoder_loss)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "epochs=100\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "samples=[] \n",
    "minibatch_loss = 0\n",
    "cost=[]\n",
    "latentvars=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        num_batches=int(21080/1)\n",
    "        for i in range(num_batches):\n",
    "            X, X_bw = datanoisefree(i)\n",
    "            Y, _ = datanoisefree(i)\n",
    "            _, temp_loss = sess.run([autoencoder_optimizer,autoencoder_loss], feed_dict={x_input:X, x_input_bw:X_bw, x_target:Y})\n",
    "\n",
    "            minibatch_loss += temp_loss / num_batches\n",
    "            latentvars.append(encoder_output)\n",
    "#             if (epoch==(epoch-1)):\n",
    "#                 latent_vector = \n",
    "        print(\"on epoch{}\".format(epoch))\n",
    "        # Print the cost every epoch\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, minibatch_loss))\n",
    "        cost.append(minibatch_loss)\n",
    "    #saving latent variables of noise free images using pickle\n",
    "        with open('lv_nf.data', 'wb') as filehandle:\n",
    "            pickle.dump(latentvars, filehandle)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights variables for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    conv1 = tf.layers.conv2d(X, 20, (3,3),strides=(2, 2), padding='valid',activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    conv2 = tf.layers.conv2d(conv1,40, (3,3),strides=(2,2),padding='valid',activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "    flat = tf.contrib.layers.flatten(conv2)\n",
    "    finallayer = tf.add(tf.matmul(flat,weights['disc_final']), bias['disc_final'])\n",
    "#     logits=tf.layers.dense(flat,units=1)\n",
    "#     output=tf.sigmoid(logits)\n",
    "    output = finallayer\n",
    "    return output\n",
    "#     return output,logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output_n = encoder_n(x_input,x_input_bw, x_input_mask)\n",
    "decoder_output_n = decoder(encoder_output_n)\n",
    "d_real = discriminator(encoder_output)\n",
    "d_fake = discriminator(encoder_output_n, reuse=True)\n",
    "\n",
    "decoder_image = decoder(decoder_input, reuse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "autoencoder_loss = tf.reduce_mean(tf.square(x_target - decoder_output))\n",
    "disc_loss = tf.reduce_mean(d_real)-tf.reduce_mean(d_fake)\n",
    "\n",
    "autoencoder_optimizer = tf.train.AdamOptimizer(learning_rate=lr,\n",
    "                                                   beta1=0.9).minimize(autoencoder_loss)\n",
    "discriminator_optimizer = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(-disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=62\n",
    "epochs=100\n",
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_n=[] \n",
    "minibatch_loss_n = 0\n",
    "cost_n=[]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        num_batches=\n",
    "        for i in range(num_batches):\n",
    "            X, X_bw, X_mask = datafornoisyimages(i)\n",
    "            Y, _ = datafornoisyimages(i)\n",
    "            _, temp_loss = sess.run([autoencoder_optimizer,autoencoder_loss], feed_dict={x_input:X, x_input_bw:X_bw, x_input_mask:X_mask, x_target:Y})\n",
    "            _, temp_loss = sess.run([discriminator_optimizer,discriminator_loss], feed_dict={x_input:X, x_input_bw:X_bw, x_input_mask:X_mask})\n",
    "            minibatch_loss_n += temp_loss / num_batches\n",
    "            \n",
    "        print(\"on epoch{}\".format(epoch))\n",
    "        # Print the cost every epoch\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, minibatch_loss_n))\n",
    "        cost_n.append(minibatch_loss_n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
