{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from scipy.misc import imread, imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 335\n",
    "# Placeholders for input data and the targets\n",
    "X_input = tf.placeholder(tf.float32, (None, img_size, img_size, 3), name='Input')\n",
    "X_input_mask = tf.placeholder(tf.float32, (None, img_size, img_size, 1), name='Input_bw')\n",
    "X_target = tf.placeholder(tf.float32, (None, img_size, img_size, 3), name='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(z,z_bw, reuse=False):\n",
    "    \"\"\"\n",
    "    Encode part of the autoencoder.\n",
    "    :param x: input to the autoencoder\n",
    "    :param reuse: True -> Reuse the encoder variables, False -> Create or search of variables before creating\n",
    "    :return: tensor which is the hidden latent variable of the autoencoder.\n",
    "    \"\"\"\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    with tf.name_scope('Encoder'):\n",
    "        filters = {1:2,2:1,3:3, 4:40, 5:50, 6:60}\n",
    "        conv1 = tf.layers.conv2d(z, filters[1], (3,3),strides=(1, 1), padding='valid',activation=tf.nn.relu, use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        conv2 = tf.layers.conv2d(z_bw, filters[2], (3,3),strides=(1,1),padding='valid',activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        conv3 = tf.layers.conv2d(conv1, filters[1], (3,3),strides=(1,1),padding='valid',activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        conv4 = tf.layers.conv2d(conv2, filters[2], (3,3),strides=(1,1),padding='valid',activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        \n",
    "        conv = tf.concat([conv3, conv4], 3)\n",
    "        #conv_shortcut = conv\n",
    "        conv5 = tf.layers.conv2d(conv, filters[3],(3,3), strides=(1, 1), padding='valid', activation=tf.nn.relu,use_bias=True, kernel_initializer='random_uniform', bias_initializer=tf.zeros_initializer())\n",
    "        print('conv1',np.shape(conv1))\n",
    "        print('conv2',np.shape(conv2))\n",
    "        print('conv3',np.shape(conv3))\n",
    "        print('conv4',np.shape(conv4))\n",
    "        print('conv5',np.shape(conv5))\n",
    "        lv = tf.contrib.layers.flatten(conv5)\n",
    "        \n",
    "    return conv5, lv, lv.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv = encoder(X_input, X_input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16_1:\n",
    "    def __init__(self, imgs, weights=None, sess=None):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "#         self.fc_layers()\n",
    "        self.map = self.pool5\n",
    "#         self.probs = tf.nn.softmax(self.fc3l)\n",
    "        if weights is not None and sess is not None:\n",
    "            self.load_weights(weights, sess)\n",
    "\n",
    "\n",
    "    def convlayers(self):\n",
    "        self.parameters = []\n",
    "\n",
    "        # zero-mean input\n",
    "        with tf.name_scope('preprocess') as scope:\n",
    "            mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "            images = self.imgs-mean\n",
    "\n",
    "        # conv1_1\n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv1_2\n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "\n",
    "        # conv2_1\n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv2_2\n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "\n",
    "        # conv3_1\n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_2\n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "\n",
    "        # conv4_1\n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "        # conv5_1\n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool5\n",
    "        self.pool5 = tf.nn.max_pool(self.conv5_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "#     def fc_layers(self):\n",
    "#         # fc1\n",
    "#         with tf.name_scope('fc1') as scope:\n",
    "#             shape = int(np.prod(self.pool5.get_shape()[1:]))\n",
    "#             fc1w = tf.Variable(tf.truncated_normal([shape, 4096],\n",
    "#                                                          dtype=tf.float32,\n",
    "#                                                          stddev=1e-1), name='weights')\n",
    "#             fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "#                                  trainable=True, name='biases')\n",
    "#             pool5_flat = tf.reshape(self.pool5, [-1, shape])\n",
    "#             fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)\n",
    "#             self.fc1 = tf.nn.relu(fc1l)\n",
    "#             self.parameters += [fc1w, fc1b]\n",
    "\n",
    "#         # fc2\n",
    "#         with tf.name_scope('fc2') as scope:\n",
    "#             fc2w = tf.Variable(tf.truncated_normal([4096, 4096],\n",
    "#                                                          dtype=tf.float32,\n",
    "#                                                          stddev=1e-1), name='weights')\n",
    "#             fc2b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "#                                  trainable=True, name='biases')\n",
    "#             fc2l = tf.nn.bias_add(tf.matmul(self.fc1, fc2w), fc2b)\n",
    "#             self.fc2 = tf.nn.relu(fc2l)\n",
    "#             self.parameters += [fc2w, fc2b]\n",
    "\n",
    "#         # fc3\n",
    "#         with tf.name_scope('fc3') as scope:\n",
    "#             fc3w = tf.Variable(tf.truncated_normal([4096, 1000],\n",
    "#                                                          dtype=tf.float32,\n",
    "#                                                          stddev=1e-1), name='weights')\n",
    "#             fc3b = tf.Variable(tf.constant(1.0, shape=[1000], dtype=tf.float32),\n",
    "#                                  trainable=True, name='biases')\n",
    "#             self.fc3l = tf.nn.bias_add(tf.matmul(self.fc2, fc3w), fc3b)\n",
    "#             self.parameters += [fc3w, fc3b]\n",
    "\n",
    "    def load_weights(self, weight_file, sess):\n",
    "        weights = np.load(weight_file)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            print(i, k, np.shape(weights[k]))\n",
    "            sess.run(self.parameters[i].assign(weights[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16_2:\n",
    "    def __init__(self, imgs, weights=None, sess=None):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "#         self.fc_layers()\n",
    "        self.map = self.pool5\n",
    "#         self.probs = tf.nn.softmax(self.fc3l)\n",
    "        if weights is not None and sess is not None:\n",
    "            self.load_weights(weights, sess)\n",
    "\n",
    "\n",
    "    def convlayers(self):\n",
    "        self.parameters = []\n",
    "\n",
    "        # zero-mean input\n",
    "        with tf.name_scope('preprocess') as scope:\n",
    "            mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "            images = self.imgs-mean\n",
    "\n",
    "        # conv1_1\n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv1_2\n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "\n",
    "        # conv2_1\n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv2_2\n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "\n",
    "        # conv3_1\n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_2\n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "\n",
    "        # conv4_1\n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "        # conv5_1\n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool5\n",
    "        self.pool5 = tf.nn.max_pool(self.conv5_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "#     def fc_layers(self):\n",
    "#         # fc1\n",
    "#         with tf.name_scope('fc1') as scope:\n",
    "#             shape = int(np.prod(self.pool5.get_shape()[1:]))\n",
    "#             fc1w = tf.Variable(tf.truncated_normal([shape, 4096],\n",
    "#                                                          dtype=tf.float32,\n",
    "#                                                          stddev=1e-1), name='weights')\n",
    "#             fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "#                                  trainable=True, name='biases')\n",
    "#             pool5_flat = tf.reshape(self.pool5, [-1, shape])\n",
    "#             fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)\n",
    "#             self.fc1 = tf.nn.relu(fc1l)\n",
    "#             self.parameters += [fc1w, fc1b]\n",
    "\n",
    "#         # fc2\n",
    "#         with tf.name_scope('fc2') as scope:\n",
    "#             fc2w = tf.Variable(tf.truncated_normal([4096, 4096],\n",
    "#                                                          dtype=tf.float32,\n",
    "#                                                          stddev=1e-1), name='weights')\n",
    "#             fc2b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "#                                  trainable=True, name='biases')\n",
    "#             fc2l = tf.nn.bias_add(tf.matmul(self.fc1, fc2w), fc2b)\n",
    "#             self.fc2 = tf.nn.relu(fc2l)\n",
    "#             self.parameters += [fc2w, fc2b]\n",
    "\n",
    "#         # fc3\n",
    "#         with tf.name_scope('fc3') as scope:\n",
    "#             fc3w = tf.Variable(tf.truncated_normal([4096, 1000],\n",
    "#                                                          dtype=tf.float32,\n",
    "#                                                          stddev=1e-1), name='weights')\n",
    "#             fc3b = tf.Variable(tf.constant(1.0, shape=[1000], dtype=tf.float32),\n",
    "#                                  trainable=True, name='biases')\n",
    "#             self.fc3l = tf.nn.bias_add(tf.matmul(self.fc2, fc3w), fc3b)\n",
    "#             self.parameters += [fc3w, fc3b]\n",
    "\n",
    "    def load_weights(self, weight_file, sess):\n",
    "        weights = np.load(weight_file)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            print(i, k, np.shape(weights[k]))\n",
    "            sess.run(self.parameters[i].assign(weights[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for deconv\n",
    "def decode(x):\n",
    "    act = tf.nn.relu(x)\n",
    "    upsample1 = tf.image.resize_nearest_neighbor(act, (512,512))\n",
    "    conv5 = tf.layers.conv2d(upsample1, 40, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    upsample2 = tf.image.resize_nearest_neighbor(conv5, (636,636))\n",
    "    conv6 = tf.layers.conv2d(upsample2, 20, (5,5), padding='same',activation=tf.nn.relu)\n",
    "    upsample3 = tf.image.resize_nearest_neighbor(conv6, (776,776))\n",
    "    conv7 = tf.layers.conv2d(upsample3, 3, (7,7), padding='same',activation=tf.nn.relu)\n",
    "    upsample4 = tf.image.resize_nearest_neighbor(conv7, (1024,1024))\n",
    "    output = tf.layers.conv2d(upsample4, 3, (7,7), padding='same',activation=tf.nn.relu)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VergilCrimson\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXjcZb338fd3srZJ06zdl7S00NLShYZddlHW1oOocFTAg1RURM9xueD4POpRzyPqOa4oxyKLuLKoUBAOgpZFlrZpaVq6pyVt0myTZbI2ySz388dMJ5M0yySZmXuW7+u6cvG7Z34z8+lczZdf79+9iDEGpZRSic9hO4BSSqnI0IKulFJJQgu6UkolCS3oSimVJLSgK6VUkki39cHFxcWmtLTU1scrpVRC2rZtW5MxpmSo56wV9NLSUsrLy219vFJKJSQROTLcc9rlopRSSUILulJKJQkt6EoplSS0oCulVJLQgq6UUkki7IIuImki8raIPDvEc1ki8piIVIrIZhEpjWRIpZRSoxvLFfrngb3DPHcb0GqMWQT8EPjuRIMppZQam7AKuojMAa4BfjnMKeuAXwWOnwQuFxGZeDyllFLhCvcK/UfAVwDfMM/PBqoBjDEeoA0oGnySiKwXkXIRKXc6neOIq1R0eTxttLS8hNvdajuKUmM26kxREbkWaDTGbBORS4Y7bYjHTto5wxizAdgAUFZWpjtrqKgpvfsvYzo/TTxcOvd51i36PVMy28nOXsiaNdvIyMiPUkKlIi+cqf8XAGtF5GogG8gTkd8YYz4Wck4NMBeoEZF0YCrQEvG0SkWc4cxpb/Lh0x5hRk5t8NGensNUVX2DxYt/ZDGbUmMzakE3xtwD3AMQuEL/0qBiDrARuAV4E7gB+LvRve1UnFswdT83nvYQpxXuHvL5Y8fuY+bM28jNPSPGyZQan3EvziUi3wTKjTEbgQeBX4tIJf4r8xsjlE+piCue1MAHFz/KebNeGfB4tzuHjYc+woqSck4v2gl4OXjwTlatehm9x68SwZgKujHmZeDlwPHXQh7vAT4UyWBKRdrk9E6uXfg4V5RuJMPhCT7u8aXx96NX8/Shm+hy57HTWcZ3LroLYzy0tb1KY+MfmD79JovJlQqPteVzlYqVwTc8Q5XXn88TB26hoXt28LHarnnMnn0XNTU/AODQoS9RVHQt6elTYppbqbHSgq6S2NA3PAEOuU7lD/tu46Br2ZCvLC39Og0Nv8XtbqCvr5YjR77NKafofDkV37Sgq6Q03A1PZ/d0njhwC1vqL2To0bZ+6el5nHLK99m372YAamp+yIwZnyAnZ0k0Yys1IVrQVdI5fPjf+fp53xnw2Ikbni8duQ6PyQjrfaZP/xh1dRtoa/sHxriprLyLFSte0BukKm7paosqqXR0bOPo0f5i7vGl8deqtXz51Qf436rrwy7mACLCokU/5cSvSWvrizQ1PRXpyEpFjBZ0lVRqazcEjw+2LuWr//g5v9u3ni533rjeb8qUVcya9elgu7LyX/F6uyecU6lo0C4XlTQ8nk4aG38XbD++/9YBo1fGInTpgJyM9/CdC39NXmY7vb1H+NLDt/HnysFz6/pV3XvNuD5TqYnSK3SVNJzOx/B6OwE41jmXg67TI/K+Xe4pPHnglmD76gV/pGRSXUTeW6lI0oKukkZod8sr1e9npFEsY/VazRUcdi0GICPNzT8vfSBi761UpGhBV0mhs3MnHR1bABDJ5I3aSyP6/gYHv957R7C9etoWVpZsjehnKDVRWtBVUqir679iLim5nk731Ih/xrttp/FK9fuC7X9esoEMR1/EP0ep8dKCrhKe19tNQ8Nvgu2ZM2+P2mc9eeAWutw5AEzPqeP9pTqMUcUPLegq4TmdT+LxuACYNGkR+fmXRO2zOtxT+dPBjwfb153yGIXZjVH7PKXGQgu6Snih3S0zZ34Skej+td5UfRVH2xcAkJXWy42nPRTVz1MqXFrQVULr6tpLW9s/ABBJZ8aMW6P+mT6Txq/39N8gPXvmP1hauCPqn6vUaLSgq4QWenVeVLSOzMzpMfncg65lvHGsfyTNx07/BWnijslnKzUcLegqYfl8vdTXPxpsz5oVvZuhQ3nswCc47pkEwOzcaq6Y/0xMP1+pwUYt6CKSLSJbRKRCRHaLyH8Mcc6tIuIUkR2Bn09GJ65S/ZzOP+PxNAOQlTWfgoIrYvr5bb2FPF3Zv5PRukW/Z2qW7o2u7AnnCr0XuMwYsxJYBVwpIucOcd5jxphVgZ9fRjSlUkOoq+ufGRqLm6FDefHIWo51zgVgUvpxPnLqwzHPoNQJo/4GGL/OQDMj8GOimkqpUXR3V+JybQq0HMyc+QkrObwmnd/s+VSwff7sTbhcr1nJolRYqy2KSBqwDVgE/MwYs3mI0z4oIhcBB4B/NcZUD/E+64H1APPmzRt3aJUaQlc8HOxDpz7CNQv9x283lnHr13cAdkaa7G1ZxZa693D2TP9om4MH72TNmm04HLqYqYqtsP6NaozxGmNWAXOAs0Vk+aBTngFKjTErgJeAXw3zPhuMMWXGmLKSkpKJ5FYpLE3cvGf2S8G2fyEuu/6w/1/o9WQB0NW1k+bmZy0nUqloTJ2OxhgX8DJw5aDHm40xvYHmA8CaiKRTagirp21hapZ/ZmhLTxE7m8osJ4KWnmm8dPTaYLup6U8W06hUFc4olxIRyQ8cTwLeC+wbdM7MkOZaYG8kQyoV6uI5LwSPX6u5Ap9Js5imn3/jab/m5mfw+XRcuoqtcK7QZwKbRGQnsBV40RjzrIh8U0TWBs65KzCksQK4C7g1OnFVqiue1MCy4rcB8Bnh1Zr3jfKK2DnSfgpNx/1diR6PC5frZbuBVMoZ9a6NMWYnsHqIx78WcnwPcE9koyl1sotm/xWH+AdZvdN0Js090ywnCiVsazif95c+Dfi7XQoLYzs2XqU2nSmqEoZDvFw458Vg+5Ua+zdDB9vWcF7wuKnpKYzxWUyjUo0WdJUwVhSXU5Dtn4nZ1pvPjsazLSc62cHWpWRk+Ltd+vrqaW9/y3IilUq0oKuEcfHckJuhx96L18TfOG9DGsXF64Jtp1NHu6jY0YKuEkJBVhMrS8qD7XgYez6c4uLrg8dNTX/GGJ1YrWJDC7pKCBfOeRGH+Puj9zSvwHl85iivsKeg4DLS0vIA6Ok5TFfXTsuJVKrQgq7inuDlotCboXF8dQ7gcGRRVHRNsK3dLipWtKCruLe8eAfFk/z7dnb05bGt4XzLiUY3uNtFqVjQgq7iXujM0NePXYbHZFhME57CwitxOLIB6OraRXd3peVEKhVoQVdxbWpmK6um9S/uGY9jz4eSnp5LQUH/LFa9SlexoAVdxbX3zH6JdIcXgP0ty6jrmms5UfhKSkK7XbQfXUWfFnQVtwQfF835a7CdKFfnJxQVXQf4Fw5rb3+L3t5jdgOppKcFXcWtJYW7mJ5TB0CXO4et9RdYTjQ2GRmF5OdfEmw3NT1tL4xKCVrQVdwKnRn6Zu2luH1ZFtOMT2i3iw5fVNGmBV3Fpb6+JtZMfyPYfrn6yhHOjl+hywC4XC/jdjdbTKOSnRZ0FZcaGh4lw+EB4JDrNGo6S+0GGqesrNnk5Z0baHl1azoVVVrQVdwxxlBX90CwHe8zQ0cTOslIu11UNGlBV3Gnvf1Nurv9uxwe90xic8jWbomouPifgsctLS/g8XRaTKOSWTh7imaLyBYRqQhsM/cfQ5yTJSKPiUiliGwWkdJohFWpIXQ0yJa6C+n1TrKYZuImT15ETs4ZABjTS0vL/1pOpJJVOFfovcBlxpiVwCrgShE5d9A5twGtxphFwA+B70Y2pkolof3M2xvPG+HMxBF6la6TjFS0hLOnqAFO/BsxI/AzeIHndcA3AsdPAveJiBhdCFqN0fHjh+nu3gNAnzeTvc1nWE40dqV3/+Wkx+ZOKeZbgWH0VceeZu2vnxpyTZqqe6856TGlwhVWH7qIpInIDqAReNEYs3nQKbOBagBjjAdoA4qGeJ/1IlIuIuVOp3NiyVVSam7uL4Z7mlfS58u2mCZyqjsW0Ng9A4DJGd0sLaqwnEglo7AKujHGa4xZBcwBzhaR5YNOkaFeNsT7bDDGlBljykpKSsaeViW90IJe4TzLYpJIkwEbSJeFjLFXKlLGNMrFGOMCXgYGz/KoAeYCiEg6MBVoiUA+lUI8nk5crk3BdoWzzGKayAtdx331tM0IXotpVDIKZ5RLiYjkB44nAe8F9g06bSNwS+D4BuDv2n+uxqq19SWM6QMgJ2cFLT3TLCeKrEOu03D1FACQl9XG4oK9lhOpZBPOFfpMYJOI7AS24u9Df1ZEvikiawPnPAgUiUgl8G/A3dGJq5JZS0t/d0tR0bUWk0SHwcH2xv4BYtrtoiItnFEuO4HVQzz+tZDjHuBDkY2mUokxvgH95/49OVvtBYqSbQ3nc9m85wE4c/qb/G7f7Qx9C0qpsdOZoioudHa+TV+ff6nc9PQi8vLOsZwoOva1nEGXOweA4klO5ucdspxIJRMt6CouDLw6vxqRNItposdr0tnReHawvWb6mxbTqGSjBV3FhdDZof7uluQVOtpljfajqwjSgq6s6+2tp6Nja6CVRkFBYq+uOJp3mlbT6/Vv1jE7t5qZOdWWE6lkoQVdWdfS8lzwOD//QjIy8i2mib4+Xza7nGuC7TO120VFiBZ0ZV1o/3lhYXJ3t5wQOmtU+9FVpGhBV1b5fL20tv412E7G8edDqXCehcfnv/G7cOpBCrMbLSdSyUALurLK5XoVr9e/mGd29ilMnnya5USx0e3JZW/zymD7zOlvWUyjkoUWdGXV4MlEIqkzyWZboy7WpSJLC7qyxhhDc/MzwXaqdLec8HbDufiM/39gpxbsYUpGm+VEKtFpQVfWdHfvp6fnMABpabnk519kOVFstfUVcLB1KQAO8bF62uBtBpQaGy3oyprQxbgKCq7A4ciymMaO0C32dJKRmigt6MqagbNDU6u75YTQ4YunF+/A42m3mEYlOi3oygq324XL9VqwXVh4tcU09jQdn8GR9oUAZDg8NDc/N8orlBqeFnRlRWvrCxDYsWfKlDKysmbYDWRR6FV6U9OfLCZRiU4LurJi4HDF1OxuOaE8ZLGu5ubn8Hp7LKZRiUwLuoo5Y7wDuhZSvaDXds6jvmsWAD5fF62tL1pOpBJVOHuKzhWRTSKyV0R2i8jnhzjnEhFpE5EdgZ+vDfVeSgG0t2/G42kGIDNzBrm5J22IlWJkwJK6TU1PWcyiEtmoW9ABHuCLxpjtIjIF2CYiLxpj9gw67zVjTGpfaqmTlN79l5Me++DiR7nuFP/xi4dW8M8bn49xqvjzduM5XLPwScDfHWWMDxH9B7Qam1H/xhhj6owx2wPHHcBeYHa0g6nktbJkS/C4wnmWxSTx45DrVNr78gBwuxvo6Ci3nEglojFdAohIKf4No4ea0naeiFSIyPMismyY168XkXIRKXc6nWMOqxJfYXYj8/KqAHD70tndvMpuoDhhSGNnyP/cQpdEUCpcYRd0EckF/gh8wRgzePbDdmC+MWYl8FNgyE5AY8wGY0yZMaaspKRkvJlVAltZ0n/lua/lDHq9kyymiS+he402NWlBV2MXVkEXkQz8xfy3xpiTBsoaY9qNMZ2B4+eADBEpjmhSlRRWlmwNHleEFDDl35pOJBOArq4KenqOWk6kEk04o1wEeBDYa4z5wTDnzAich4icHXjf5kgGVYkv09HD6UUVwbb2nw/U451Mfv4lwXbo0ghKhSOcK/QLgI8Dl4UMS7xaRO4QkTsC59wAvCMiFcBPgBuNMSZKmVWCWlq0k8y0PgCOdc7FeTx1Z4cOp6jouuCx9qOrsRp12KIx5h/AiLsOGGPuA+6LVCiVnAZ2t+jV+VCKiq6lsvJzALS2/h2Pp5P09FzLqVSi0IGuKkbMwIKu3S1DmjSplJyc5QAY00dr60uWE6lEogVdxcTcKe9SNKkJgC53DpWupZYTxS/tdlHjpQVdxUTocMVdTWvwmnAmKaemgQXdP2tUqXBoQVcxMWB2qPafjygv72wyMvzzNPyzRreO8gql/LSgq6ibktHGKfn7AfAZB7uazrScKL6JpFFUdE2wrZOMVLi0oKuoO6NkGw7xj2KtdC2h0z3VcqL4p/3oajy0oKuoGzi6pcxiksRRUPC+kFmjO+npOWI5kUoEWtBVVKWJhzOKtwXbOt0/POnpueTnXxpsh+7wpNRwtKCrqFpcsIfJGd0ANB0voaZzvuVEiSN0JyftdlHh0IKuourkyUQjTjpWIYqL+/vRT8waVWokWtBVVK3S6f7jlp09n5ycM4ATs0Z1r1E1Mi3oKmq6uyuZmVsDQK83i70tKywnSjw62kWNhRZ0FTUtLf038vY2r8Dty7KYJjHprFE1FlrQVdSErue9w6mjW8bDP2t0GgBudyPt7VtGeYVKZVrQVVR4PB24XK8E29p/Pj4ijgGzRrXbRY1EC7qKitbWFzHGDcDR9gW09uqOhOM1sNtFdzFSw9OCrqKiqal/n3Bd+3xiCgqu0FmjKiyjrmEqInOBR4EZgA/YYIz58aBzBPgxcDXQDdxqjNke+bgqEfh8fTQ1bQy2tzWcZzFNYim9e+gZoV9cs5wzSvy/Up996F7+dvTak86puveakx5TqSWcK3QP8EVjzFLgXOCzInL6oHOuAhYHftYD90c0pUoora1/w+ttA6Dp+DSq2hdZTpT4Qm8qryrRG6NqaKMWdGNM3YmrbWNMB7AXmD3otHXAo8bvLSBfRGZGPK1KCE7nk8HjrfUXoLNDJ25HyBo4S4p2kp3WbTGNildj6kMXkVJgNbB50FOzgeqQdg0nF31EZL2IlItIudPpHFtSlRB8PveA/vPy+gsspkkezT3TONpeCkCGw8Oy4h12A6m4FHZBF5Fc4I/AF4wx7YOfHuIl5qQHjNlgjCkzxpSVlJSMLalKCC7Xy3g8LQBkZc3hcNuplhMljx3Oc4LH2u2ihhJWQReRDPzF/LfGmD8NcUoNMDekPQeonXg8lWhCu1uKiz+I0YFUERPa7bKyZCuC12IaFY9G/W0LjGB5ENhrjPnBMKdtBG4Wv3OBNmNMXQRzqgTg83loavpzsF1ScoPFNMnn3bbFtPXmA5CX1cbCqQctJ1LxJpzLpwuAjwOXiciOwM/VInKHiNwROOc54DBQCTwAfCY6cVU8a2t7Dbfbf28kM3MmU6eebzlRcjE4Buz4tGqadruogUYdh26M+QejDFMwxhjgs5EKpRLTwO6W6xHR7pZI29F4NhfNeQnwF/Q/HrzZciIVT/Q3TkWEMV6amvpvr2h3S3Tsbl6N2+e/Dps7pYqi7EbLiVQ80YKuIqKt7Q36+uoByMgoIT//QsuJklOvdxJ7m1cG26umDR5BrFKZFnQVESd3t6RZTJPcQke7aD+6CqUFXU2YMT7tbomhHSGLnS0p3KWzRlWQFnQ1Ye3tW+jt9W81l55eRH7+xZYTJbeWnmkcbV8A6KxRNZAWdDVhA7tb1uFwZFhMkxoGdLvorFEVoAVdTYgxZkBB1+6W2AhdfVFnjaoTtKCrCeno2EZvr3/DhbS0qRQUXG45UWo4adZo/gHLiVQ80IKuJuTk7pZMi2lSh3/WaP/NUe12UaAFXU2AdrfYpcMX1WBa0NW4dXZW0NNzCIC0tCkUFFxhOVFqead5NW6v/wb03ClHOH68ym4gZZ0WdDVuoVfnRUXXkZaWbTFN6unzZrOnZUWw3dz8jMU0Kh5oQVfj4u9ueSLY1u4WO3Y09m960dz8rMUkKh5oQVfj0tW1m+PH/SMrHI4cCguvtJwoNYXeGPXvFtVhMY2ybdTlc5UqvfsvJz32gUW/5QOL/MdvHjuTm7/69xinUgAtPSUcbV/AvLx3MaaP1ta/UlLyQduxlCV6ha7GZc30N4LHuhG0XaGjXZqaNlpMomzTgq7GbGZONXOn+CcT9Xqz2Nm0xnKi1La98dzgcVPTn/B4Oi2mUTaFs6foQyLSKCLvDPP8JSLSFrI93dciH1PFk7KQq/NdzjX0eidZTKOq2hdxrNO/R7vX24nT+bjlRMqWcK7QHwFGu+P1mjFmVeDnmxOPpeJZ2YzXg8dbG7S7xT7htZr+OQB1dQ9azKJsGrWgG2NeBVpikEUlgGmTa5mfdxgAtzeDisazRnmFioXXay9DxD/Gob39Dbq69lpOpGyIVB/6eSJSISLPi8iy4U4SkfUiUi4i5U6nM0IfrWIptLvlnebV9HgnW0yjTujoy6eoaG2wXV//kMU0ypZIFPTtwHxjzErgp8BTw51ojNlgjCkzxpSVlJRE4KNVrA3obtHRLXFl5szbgsf19Y/i87ktplE2TLigG2PajTGdgePngAwRKZ5wMhV3iic1sHDqQQA8vvQBsxSVfYWF7yczczYAbnejzhxNQRMu6CIyQ0QkcHx24D2bJ/q+Kv6UTe+/Ot/dvJJuT67FNGowkTRmzLg12Nabo6knnGGLvwfeBE4TkRoRuU1E7hCROwKn3AC8IyIVwE+AG40xJnqRlS2h3S06mSg+zZz5L8Hjlpbn6e09ZjGNirVRp/4bY24a5fn7gPsilkjFpcJsJ4vy9wPg9TkGTGZR8WPSpIXk51+Ky7UJ8FFf/yvmz/9327FUjOhMURWW0Kn+e1tW0uXOs5hGjST05mhd3UMY47OYRsWSFnQVltDhijq6Jb4VF19PWtpUAHp6DuFyvWo5kYoVLehqVFOzWlhcsAcAn9HulniXljaJ6dM/GmzX1+vN0VShBV2Nas20N3GI/z73vpbldPTlW06kRhPa7eJ0Ponb7bKYRsWKFnQ1Kh3dknimTDmT3NxVAPh8PTQ2/t5yIhULWtDViPr6GllS6F9o02eEbY3nWU6kwjVjRujNUe12SQVa0NWImpqewiH+URIHW0+nrbfQciIVrunTP4pIFgCdndvo7KywnEhFmxZ0NSKn88ngsS6Vm1gyMgooKbk+2Nar9OSnBV0Ny+1uprW1f6/QbfXnW0yjxiP05mhDw2/wenssplHRpgVdDaup6WnAC0Cl6zRae3XNtUSTn38p2dkLAPB4WmlqGnYxVJUEtKCrYTU0/DZ4rKNbEpOIgxkzPhFs65j05KYFXQ2pvX0rLpe/u8VnHGypf4/lRGq8/CswCgCtrS9x/HiVzTgqirSgqyEdPfr/gseb6y6kpWeaxTRqIrKz51JY+P5gu77+YYtpVDSNutqiSj1dXbsH9LU+e/hDFtOocJXe/Zdhnyubvoo7V/8vANv33c9lv1iDIS34fNW910Q9n4o+vUJXJzl69N7gcVHROo51ltoLoyJiR+M5dPT5V8gsmuRkWfEOy4lUNGhBVwMcP36Yhob+aeLz599jMY2KFI/J4I3aS4Pti2a/aDGNihYt6GqAo0e/x4mhivn5l5OXp/uGJotXa64IHp85/S1yM9osplHREM4WdA+JSKOIvDPM8yIiPxGRShHZKSJnRj6mioXe3toBN8x0p5vkcqyzlEOuUwFId3g4b9bLdgOpiAvnCv0R4MoRnr8KWBz4WQ/cP/FYyobq6h9gTB8AU6acQ37+paO8QiWaV2veFzy+aM6LgG7/m0xGLejGmFeBlhFOWQc8avzeAvJFZGakAqrYcLubqa39n2B7/vyvIiIWE6lo2Fx3Eb0e/4Jdc6dUsSDvoOVEKpIi0Yc+G6gOadcEHjuJiKwXkXIRKXc6nRH4aBUpNTU/xefrAiAn5wyKinQYWzLq8U5ma0P/JLGL5vzVYhoVaZEo6ENdxg357zhjzAZjTJkxpqykpCQCH60iwePp4NixnwTb8+bdg4jeL09WoTdHz5n5KpkOXbArWUTit7YGmBvSngPURuB9VYzU1v4PHk8rANnZp1BSohOJktmB1mXUdfn/ET05o3vAjlQqsUWioG8Ebg6MdjkXaDPG1EXgfVUMeL09VFf/d7A9b97dOBw6gTi5Ca+FXKX7b46qZBDOsMXfA28Cp4lIjYjcJiJ3iMgdgVOeAw4DlcADwGeillZFXH39w7jdDQBkZs5mxoyPW06kYuH1Y5fj9fl//ZcUvkN3t94cTQajXooZY24a5XkDfDZiiVTM+Hxuqqu/F2zPnfslHI4si4lUrLT1FVDhPIszp28GoL7+IRYu/I7lVGqi9M5XCmts/AM9PVUAZGQUM2vW7XYDqZgKHZNeX/8rfD6PxTQqErSgpyhjfBw92n9FNmfOF0hLy7GYSMXazqYyXD0FAPT11dHS8rzlRGqitKCnqKamp+ju3gtAWtoUZs3SXrNU4zNpvF57ebBdV/dLi2lUJGhBT0HGGI4c6d/AYvbsz5KRkW8xkbIldEx6c/NGXK5XLKZRE6Xj01JE6OYHy4q28+WztgHQ583kA48so71v+M0RVPJq6J5Nef35lM14A4D9+9dTVlZBWlq25WRqPPQKPQVdd8rjweNXa95He1+BxTTKtt/sXU9amn/zi+PHD3DkyLctJ1LjpQU9xSzK38OSQv9KyB5fGs+9e73lRMo2V28xCxf271JVXf1dOjt3WUykxksLeoq5bmH/1fkbtZfq5s8KgFmzPkVe3gUAGONh//7bMcZrOZUaKy3oKWTelMOsnFYOgM8Iz717g+VEKl6IODjttA2IZADQ0bGZY8d+bjmVGist6CnkmoVPBI/L6y+gvmuOxTQq3uTknM68ef27VL377r/T01M9witUvNGCniKmTz7GWTP+EWw/e/jDFtOoeDV//j1MnrwUAK+3k4MHP4N/dQ+VCLSgp4hrFj6BQ/y/mBWNZRztWGg5kYpHDkcWp566Idhubn4Wp/OJEV6h4okW9BTQ03OU82dtCraf0atzNYL8/Pcwa9YdwfbBg3fhdrdaTKTCpQU9BVRX/xfpDv+IhX0ty6l0nW45kYp3CxfeS2bmLADc7gYOHfqy5UQqHFrQk1xfXyN1dQ8E288e1t2I1OjS06eyePHPgu36+gdpbX3ZXiAVFp36n+Rqan6Ez+ffM/LdtkW803Sm5UQqHoUuDdEvgztX9S8L8MIbH+X/vv5T3L6T18yvulc3FY8HeoWexFyu1wZsL+cf2TLUnt5KDe03ez9Ft9u/rPKMnFrWnvKY5URqJMEq4AwAAAwkSURBVGEVdBG5UkT2i0iliNw9xPO3iohTRHYEfj4Z+ahqLLq69vHOO+swpg+AI+0L2d5wruVUKtG4eot4/MCtwfZVC/7InNx37QVSIwpnT9E04GfAVcDpwE0iMtRdtceMMasCP7qwskV9fQ3s2nUVHo9/ZEJGxnR++vZXMfoPMjUOr1S/n/0tywBId3j5xPKfIuiyAPEonN/ws4FKY8xh47/c+wOwLrqx1Hh5vV3s2nVtcGs5h2MyK1b8habj0+0GUwnL4OCR3Xfi9vlvuZ2Sf4DL5+tyy/EonII+Gwid/1sTeGywD4rIThF5UkTmDvVGIrJeRMpFpNzpdI4jrhqJz+dhz54b6egoDzziYNmyx5kyZY3VXCrx1XXN5ZlDHwm2b1j8KIXZjRYTqaGEU9CHuos2eC7wM0CpMWYF8BLwq6HeyBizwRhTZowpKykpGVtSNSJjDJWVd9Hc/GzwsVNP/TlFRTr6QEXGXw7fwLGOeQBkp/dw8+n3c3IpUDaFU9BrgNAr7jlAbegJxphmY0xvoPkAoJeEMVZd/V/U1t4fbM+bdzezZn3KYiKVbLwmg4d3fw6f8V/jrZq2lbNnvGY5lQoVTkHfCiwWkQUikgncCGwMPUFEZoY01wJ7IxdRjaax8TEOH/5KsD1t2k0sWPCfFhOpZFXpWsqmo1cH2x9duoGcjA6LiVSoUQu6McYD3Am8gL9QP26M2S0i3xSRtYHT7hKR3SJSAdwF3BqtwGogl+s19u69OdieOvVilix5GBEd0aKi44kDt9DSUwTA1CwXHz71YcuJ1Alia2nMsrIyU15ePvqJalhdXft4++3zg8MTJ09eyurVr5ORcfIeoUPPBFRqfFZPe4vPn9m/9+jKlZsoKLjEXqAUIiLbjDFlQz2nl3EJaqix5mec8dyQxVypSHu78Vy21p8fbO/f/y90dx+0mEiBruWSMEKvsDPTerj77HtYOLUKgF5PFl9/4x6OPLMb2G0noEo5v9l7B8uKKpic0UVPz7ts27aGJUsepqTkg7ajpSy9Qk8wDvHymZXfZeFU/9WQzzj4ecXdHGlfZDmZSjVtvYX8ctfncXv9+5B6vR3s3n0DlZX/hs/ntpwuNWlBTyiGjy79BaumbQ0+8uieT1PhPMtiJpXKtjeez7c3f5/s7AXBx2pqfsiOHZfQ23vMYrLUpAU9gVxV+icun/dcsP3s4Rt4ufoqi4mUgiPti1izZhtFRWuDj7W3v0F5+WpaW/9mMVnq0YKeIM6e8SofWdI/POzN2ov544GbR3iFUrGTkVHA8uVPsXDhd4E0ANxuJxUVV1BV9W2M8dkNmCK0oCcAl+s1bl/xg2B7X8tyHtz1BV09UcUVEWHevK+watXfyMycEXjUUFX1f9m161rc7mar+VKBVoQ41ttbx8GDn6ei4goyHB4AjnXO5Sfb/w8ek2E5nVJDy8+/mDVrtjN16sXBx1panqe8/Eza27dYTJb8dGJRHOrra+Do0e9SW3t/cPs4gLbefL711n/rUrgqITjEy/WLf821C58MPubxpfO7vbfz9+qrObHun25fNzYjTSzScehxpK/PSXX19zh27Gf4fMcHPHfYtZgH3/m8FnOVMHwmjScP3Epl61JuX/EDcjK6SHd4uHnZ/Swu2MMju++k1zvJdsykogU9DvT1NVFd/V8cO3YfPl/XgOdyc9ewYMF/cOv3DbofqEpEO5zn8I03fsxnV32H0qmHADhv1ivMyzvMfW//u+V0yUX70C1yu1s4fPirbN68gOrq7w4o5rm5q1i+/GnWrNkaWNNci7lKXM7jM/jPzd9nU/WVwcdm51bz9fP+lbq6B/F6j4/wahUuvUK3wO1upabmh9TU/Aivd+DSozk5Kygt/QbFxR9ARIu4Sh5uXya/2n0nB1uXcsuyn5OV1kt2eg/793+Sgwc/R0HB+yguXktR0bVkZk6zHTchaUGPIY+njZqaH1Nd/QO83rYBz02evIzS0m9QUnK9Ln2rktobtZdztP0UPrv6O8zM8c8m9fmO09z8NM3NTwNCXt55geK+lsmTl+jFTZh0lEsUGePj+PFDdHZW0NGxhb2H7ic3s3PAOcc65/J05U1srX+PjitXKSU7rZurF/yRG1dU0N29b9jzJk1aRFHROoqL15KXdz4OR2pfh440ykULeoR4PB10de2is7OCzs4Kuroq6OzcddJNzhPqumbzdOVNbK67EBOYWadUKqq69xq6uw/Q3PwMTU1P09b2OjD0zNL09EKKiq6huHgdBQXvIz19SmzDxgEt6BFkjKGnpyqkaFfQ2bmTnp5DYb2+vmsmGw/dxFt1F+MzWsiVGiw3o40VJeWsnraZM4q3k53eM+R5bl86xQUXkJ09n6ysWWRmziQzc1bgeBaZmTNIS8uOcfrom3BBF5ErgR/jX6Thl8aYewc9nwU8in9z6GbgI8aYqpHe02ZBN8aLx9OO19s+wn/bhnjMRXf3frze9rA/KyNjGrm5K8nNXclXNmbyduM5WsiVClOGo48lhTs5c9pbrJq2hYLsljG9Pj29cIhiP5OsrFlkZEzH4cjG4cgK/ohkDWrH3+/qhAq6+P9EB4ArgBr8m0bfZIzZE3LOZ4AVxpg7RORG4J+MMR8Z6X3HU9Dd7mZ27/4QxngxxhP8Lwxsj/b84Ek7keD1Oajtmkt1xwKq2xdwtGMB1R0LaO/THYSUigTBx/y8Q4Hivpl5eVUx+NS0YQu+vzQK4AjctHUAEhjUMNRj/f8FBwsWfIu8vLEvfT3RmaJnA5XGmMOBN/sDsA7YE3LOOuAbgeMngftEREyE+3OM8eJybYrkW45LZ9+UYMGu7ljA0fYF1HbO0/VVlIoig4Oq9sVUtS/mT5Ufpyi7kVm5RynIaiE/u5mpWa3+46xm8rNbmJrZSppjoqs8evH5uvH5uiPyZwg1Z87nI/6e4RT02UB1SLsGOGe4c4wxHhFpA4qAptCTRGQ9sD7Q7BSR/eMJbV8HsDPwc5JiBv251Un0OxqdfkejOALF2xP6O7p6vC+cP9wT4RT0oQaADr7yDuccjDEbgA1hfGbCEpHy4f45pPz0Oxqdfkej0+/oZOEMfK4B5oa05wC1w50jIunAVGBsdy+UUkpNSDgFfSuwWEQWiEgmcCOwcdA5G4FbAsc3AH+PdP+5UkqpkY3a5RLoE78TeAH/sMWHjDG7ReSbQLkxZiPwIPBrEanEf2V+YzRDx7mk7lKKEP2ORqff0ej0OxrE2sQipZRSkaWLhyilVJLQgq6UUklCC/o4iciVIrJfRCpF5O4hnv83EdkjIjtF5G8iMuzY0WQ12ncUct4NImJEJOWGoIXzHYnIhwN/l3aLyO9indG2MH7X5onIJhF5O/D7Nu4B3gnPGKM/Y/zBf3P4ELAQyAQqgNMHnXMpMDlw/GngMdu54+07Cpw3BXgVeAsos5073r4jYDHwNlAQaE+znTsOv6MNwKcDx6cDVbZz2/rRK/TxCS6HYIzpA04shxBkjNlkjDkxX/gt/OP3U8mo31HAt4DvAUMvqZfcwvmObgd+ZoxpBTDGNMY4o23hfEcGyAscT+XkeTIpQwv6+Ay1HMLsEc6/DXg+qoniz6jfkYisBuYaY56NZbA4Es7fo1OBU0XkdRF5K7DyaSoJ5zv6BvAxEakBngM+F5to8Se1t/4Yv7CWOgAQkY8BZcDFUU0Uf0b8jsS/7NwPgVtjFSgOhfP3KB1/t8sl+P+V95qILDfGuKKcLV6E8x3dBDxijPlvETkP/5yY5caYia7MlXD0Cn18wlkOARF5L/BVYK0xpjdG2eLFaN/RFGA58LKIVAHnAhtT7MZouMtqPG2McRtj3gX24y/wqSKc7+g24HEAY8ybQDb+xc1Sjhb08Rl1OYRAd8Iv8BfzVOv3hFG+I2NMmzGm2BhTaowpxX+fYa0xJvG2sRq/cJbVeAr/DXZEpBh/F8zhmKa0K5zv6ChwOYCILMVf0J0xTRkntKCPg/HvmnFiOYS9wOMmsByCiKwNnPZ9IBd4QkR2iMjgv4RJLczvKKWF+R29ADSLyB5gE/BlY0yzncSxF+Z39EXgdhGpAH4P3GoCQ15SjU79V0qpJKFX6EoplSS0oCulVJLQgq6UUklCC7pSSiUJLehKKZUktKArpVSS0IKulFJJ4v8DsbBnRPFi3goAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_normal_distribution(input_shape):\n",
    "    mu, sigma = 0.0, 1.0\n",
    "    norm_dist = np.random.normal(mean, sigma, input_shape)\n",
    "    count, bins, ignored = plt.hist(norm_dist, 20, normed=True)\n",
    "    return norm_dist\n",
    "# # Plot the distribution curve\n",
    "# plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "#     np.exp( - (bins - mu)**2 / (2 * sigma**2) ),       linewidth=3, color='y')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input_tensor):\n",
    "    # if input tensor is a 3D array of size Nh x Nw X Nc\n",
    "    # we reshape it to a 2D array of Nc x (Nh*Nw)\n",
    "    channels = int(input_tensor.shape[-1])\n",
    "    a = tf.reshape(input_tensor, [-1, channels])\n",
    "    n = tf.shape(a)[0]\n",
    "\n",
    "    # get gram matrix \n",
    "    gram = tf.matmul(a, a, transpose_a=True)\n",
    "\n",
    "    return gram\n",
    "\n",
    "def get_style_loss(base_style, gram_target):\n",
    "    height, width, channels = base_style.get_shape().as_list()\n",
    "    gram_style = gram_matrix(base_style)\n",
    "    # Original eqn as a constant to divide i.e 1/(4. * (channels ** 2) * (width * height) ** 2)\n",
    "    return tf.reduce_mean(tf.square(gram_style - gram_target)) / (channels**2 * width * height) #(4.0 * (channels ** 2) * (width * height) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstruction loss\n",
    "def reconstruction_loss(x_target, reconstructed_image):\n",
    "    lr=0.001\n",
    "    L2_loss = tf.reduce_mean(tf.square(x_target - reconstructed_image))\n",
    "    style_loss = get_style_loss(reconstructed_image, x_target)\n",
    "    reconstruction_loss = L2_loss + style_loss\n",
    "    reconstruction_optimizer = tf.train.AdamOptimizer(learning_rate=lr,\n",
    "                                                       beta1=0.9).minimize(reconstruction_loss)\n",
    "    return reconstruction_loss, reconstruction_optimizer\n",
    "\n",
    "#KL divergence loss\n",
    "def KLdivergence_loss(encode_LD, groundtruth_LD, normal_dist):\n",
    "    k = tf.keras.losses.KLDivergence()\n",
    "    kl_loss = k(encode_LD, groundtruth_LD) + k(encode_LD, normal_dist) + k(groundtruth_LD, normal_dist)\n",
    "    return kl_loss\n",
    "\n",
    "#wgan loss\n",
    "def wgan_loss(d_real, d_fake):\n",
    "    lr=0.01\n",
    "    disc_loss = tf.reduce_mean(d_real)-tf.reduce_mean(d_fake)\n",
    "    discriminator_optimizer = tf.train.RMSPropOptimizer(learning_rate=lr).minimize(-disc_loss)\n",
    "    return disc_loss, discriminator_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-04967e33af68>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\VergilCrimson\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\VergilCrimson\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "conv1 (?, 333, 333, 2)\n",
      "conv2 (?, 333, 333, 1)\n",
      "conv3 (?, 331, 331, 2)\n",
      "conv4 (?, 331, 331, 1)\n",
      "conv5 (?, 329, 329, 3)\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\VergilCrimson\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 335 and 1024 for 'sub' (op: 'Sub') with input shapes: [?,335,335,3], [?,1024,1024,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1606\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1607\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 335 and 1024 for 'sub' (op: 'Sub') with input shapes: [?,335,335,3], [?,1024,1024,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-94612bb438dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreconstructed_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mreconst_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconst_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstructed_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mkl_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKLdivergence_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_LD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdisc_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwgan_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstructed_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-64b59d4a02bf>\u001b[0m in \u001b[0;36mreconstruction_loss\u001b[1;34m(x_target, reconstructed_image)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreconstruction_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreconstructed_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mL2_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_target\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mreconstructed_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mstyle_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_style_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconstructed_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mreconstruction_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL2_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstyle_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  11084\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11085\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m> 11086\u001b[1;33m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m  11087\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11088\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[1;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3355\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[1;32m-> 3357\u001b[1;33m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[0;32m   3358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3359\u001b[0m   def _create_op_internal(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3426\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3428\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1770\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1771\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1608\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1610\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1612\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 335 and 1024 for 'sub' (op: 'Sub') with input shapes: [?,335,335,3], [?,1024,1024,3]."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "#     sess = tf.Session()\n",
    "#     conv, ld = encoder(X_input, X_input_mask)\n",
    "    vgg1 = vgg16_1(X_input, 'vgg16_weights.npz', None)\n",
    "    vgg2 = vgg16_2(X_input_mask, 'vgg16_weights.npz', None)\n",
    "    conv, ld, ld_shape = encoder(vgg1.pool5, vgg2.pool5)\n",
    "    \n",
    "    reconstructed_image = decode(conv)\n",
    "    norm_D = make_normal_distribution(ld_shape)\n",
    "    reconst_loss, reconst_opt = reconstruction_loss(X_target, reconstructed_image)\n",
    "    kl_loss = KLdivergence_loss(ld, gt_LD, norm_D)\n",
    "    disc_loss, disc_opt = wgan_loss(X_target, reconstructed_image)\n",
    "    \n",
    "    batch_size=62\n",
    "    epochs=100\n",
    "    init=tf.global_variables_initializer()\n",
    "    samples_n=[] \n",
    "    minibatch_loss_n = 0\n",
    "    cost_n=[]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            num_batches=56\n",
    "            for i in range(num_batches):\n",
    "#                 X, X_bw, X_mask = datafornoisyimages(i)\n",
    "#                 Y, _ = datafornoisyimages(i)\n",
    "                _, temp_loss = sess.run([reconst_opt,reconst_loss], feed_dict={x_input:X, x_input_bw:X_bw, x_input_mask:X_mask, x_target:Y})\n",
    "                _, temp_loss = sess.run([disc_opt,disc_loss], feed_dict={x_input:X, x_input_bw:X_bw, x_input_mask:X_mask})\n",
    "                minibatch_loss_n += temp_loss / num_batches\n",
    "\n",
    "            print(\"on epoch{}\".format(epoch))\n",
    "            # Print the cost every epoch\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, minibatch_loss_n))\n",
    "            cost_n.append(minibatch_loss_n)\n",
    "        \n",
    "#     img1 = imread('laska.png', mode='RGB')\n",
    "#     img1 = imresize(img1, (224, 224))\n",
    "\n",
    "#     prob = sess.run(vgg.probs, feed_dict={vgg.imgs: [img1]})[0]\n",
    "#     preds = (np.argsort(prob)[::-1])[0:5]\n",
    "#     for p in preds:\n",
    "#         print class_names[p], prob[p]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
